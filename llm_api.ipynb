{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7079478",
   "metadata": {},
   "source": [
    "# uv for pacakge management\n",
    "\n",
    "```\n",
    "uv sync\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedcc052",
   "metadata": {},
   "source": [
    "# Ollama and Local models\n",
    "\n",
    "https://ollama.com/\n",
    "\n",
    "https://ollama.com/library\n",
    "\n",
    "```\n",
    "ollama run gemma3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37233b7e",
   "metadata": {},
   "source": [
    "# API from frontier model providers\n",
    "\n",
    "Following OpenAI's API format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2834c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖOpenAI API Key exists and begins sk-proj-\n",
      "‚úÖAnthropic API Key exists and begins sk-ant-\n",
      "‚úÖGoogle API Key exists and begins AIzaSyAF\n",
      "‚ùåGroq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"‚úÖOpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"‚ùåOpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"‚úÖAnthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"‚ùåAnthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"‚úÖGoogle API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"‚ùåGoogle API Key not set\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"‚úÖGroq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"‚ùåGroq API Key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582187a",
   "metadata": {},
   "source": [
    "# Basic LLM Call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ee634",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(base_url=gemini_url, api_key=google_api_key)\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "anthropic = OpenAI(base_url=anthropic_url, api_key=anthropic_api_key)\n",
    "groq = OpenAI(base_url=groq_url, api_key=groq_api_key)  \n",
    "ollama = OpenAI(base_url=\"http://localhost:11434/v1/\", api_key=\"\")  # No API key needed for Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23bb6a",
   "metadata": {},
   "source": [
    "# System Prompt and User Prompt\n",
    "\n",
    "| Aspect | System Prompt | User Prompt |\n",
    "|---|---|---|\n",
    "| Primary Purpose | Define the model‚Äôs role, behavior, boundaries, and global rules | Specify the actual task, question, or request |\n",
    "| Provided By | System / Developer | End user |\n",
    "| Scope of Influence | Global (affects the entire conversation) | Local (affects only the current request) |\n",
    "| Priority | **Highest** (overrides all other prompts) | Lower (must comply with the system prompt) |\n",
    "| Typical Content | Role definition, tone, style, constraints, safety rules | Questions, instructions, data, requirements |\n",
    "| Visibility to User | Usually hidden from the user | Visible to the user |\n",
    "| Usage Frequency | Usually set once at the start of a conversation | Can change every turn |\n",
    "| Example | ‚ÄúYou are a strict Python tutor. Respond in clear, concise English.‚Äù | ‚ÄúExplain Python generators with examples.‚Äù |\n",
    "| Design Focus | Consistency, safety, and behavior control | Clarity and task specificity |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5229f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-807', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Okay, let‚Äôs imagine what it might be like to be a Martian! This is, of course, entirely speculative, as we haven't actually encountered any Martians yet. We‚Äôre basing this on what we know about Mars ‚Äì its environment, geology, and what scientists theorize about potential evolution ‚Äì and trying to build a plausible picture. \\n\\nHere‚Äôs a breakdown, broken down into different aspects of a Martian life:\\n\\n**1. The Physical Reality - A Harsh, Beautiful World:**\\n\\n* **Low Gravity:** You‚Äôd feel incredibly light. Jumping would be ridiculously high, and movement would be bouncy and floaty. It would take time to get used to, and probably impact bone density over generations.\\n* **Thin Atmosphere:** The air would be incredibly thin ‚Äì around 1% of Earth‚Äôs.  You‚Äôd need a pressurized suit *constantly* outside. The pressure is too low for our bodies to function normally.\\n* **Extreme Temperatures:** Mars is bitterly cold. Average temperatures are around -62¬∞C (-80¬∞F).  Temperatures fluctuate wildly, and sunlight can quickly warm the surface, followed by rapid cooling at night. You'd need incredible adaptations to survive.\\n* **Red Landscape:** You‚Äôd be surrounded by vast deserts of red iron oxide (rust).  Think canyons, mesas, and plains‚Ä¶ and a whole lot of dust! \\n* **Radiation:** The lack of a global magnetic field and a thin atmosphere means you'd be constantly bombarded with harmful radiation. \\n\\n\\n**2. Potential Biology - How Might They Adapt?**\\n\\nThis is where things get *really* interesting and speculative. Here are a few possibilities, based on what scientists suggest might be possible:\\n\\n* **Microbial Life (Most Likely):**  The earliest Martian life, if it exists, would almost certainly be microbial ‚Äì bacteria and archaea. They‚Äôd likely be found underground, where they'd be shielded from radiation and find pockets of liquid water.\\n* **Radiation-Resistant Organisms (If More Complex):** If more complex life evolved, they'd *need* to be incredibly resistant to radiation. This might manifest in a few ways:\\n    * **Thick, Pigmented Skin:** A thick layer of skin, possibly heavily pigmented (dark red or black) to absorb radiation, is a common theory.\\n    * **DNA Repair Mechanisms:**  Extremely efficient DNA repair systems to constantly fix radiation damage.\\n    * **Shielding:**  Perhaps they'd evolve internal structures, like dense bone marrow, to provide shielding.\\n* **Size and Mobility:**  Due to the low gravity, smaller, more agile creatures would likely be favored.  Think six limbs for stability, or perhaps something even more flexible.\\n* **Diet:** They might be chemotrophs - organisms that derive energy from chemical reactions rather than sunlight (like some bacteria on Earth). Or, if liquid water was more accessible, they could be adapted to consuming the mineral-rich soils.\\n* **Eyesight:** Large, sensitive eyes would be crucial for navigating the dim light and spotting potential food sources or dangers.\\n\\n**3. What Might Their Lives Be Like?**\\n\\n* **Underground Dwellings:**  It‚Äôs highly probable that any evolved Martians would live primarily underground, taking advantage of shelter from radiation and temperature extremes. They might create cave systems or tunnel networks.\\n* **Nomadic Lifestyle (Possibly):**  Depending on the availability of resources, they might be nomadic, following seasonal changes and tracking water sources.\\n* **Social Structure:** It's impossible to say, but they might live in small, closely-knit groups for mutual protection and cooperation.\\n* **Culture & Technology (Very Speculative):** If they developed intelligence, their technology would be radically different ‚Äì likely based on harnessing geothermal energy or manipulating minerals. Their culture would be shaped by the challenges of their environment.\\n\\n\\n**Important Note:** We're talking about *hypothetical* Martians. This is based on our current understanding of science and what we *hope* to find. It‚Äôs a fascinating thought experiment, and the reality could be far more surprising!\\n\\n---\\n\\n**Resources for Further Exploration:**\\n\\n* **NASA Mars Exploration Program:** [https://mars.nasa.gov/](https://mars.nasa.gov/) - This website has tons of information about current and past Mars missions.\\n* **Smithsonian Magazine - What Would a Martian Look Like?:** [https://www.smithsonianmag.com/science-nature/what-would-a-martian-look-like-180976751/](https://www.smithsonianmag.com/science-nature/what-would-a-martian-look-like-180976751/)\\n\\n\\nWould you like me to expand on any particular aspect of this, such as:\\n\\n*   The potential for Martian microbes?\\n*   The challenges of building a Martian colony?\\n*   A more detailed look at their physical adaptations?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1766452349, model='gemma3', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=1057, prompt_tokens=30, total_tokens=1087, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "        model = 'gemma3',\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"What is it like to be a martian?\"}\n",
    "        ]\n",
    ")\n",
    "\n",
    "response # Output\n",
    "#response.choices[0].message.content  # What we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884c0c1",
   "metadata": {},
   "source": [
    "# Stateless of LLM and illusion of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b415b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_ollama(user_input):\n",
    "    response = ollama.chat.completions.create(\n",
    "        model = 'gemma3',\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb99cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Adam! It's nice to meet you. üòä \n",
      "\n",
      "What can I help you with today? Do you have a question, need some information, or just want to chat?\n",
      "As an AI, I have no way of knowing your name! I don't have access to personal information. üòä \n",
      "\n",
      "You'll have to tell me your name! üòÑ \n",
      "\n",
      "What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "response1 = chat_with_ollama(\"Hi, I am Adam\")\n",
    "print(response1)\n",
    "\n",
    "response2 = chat_with_ollama(\"What is my name?\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29669871",
   "metadata": {},
   "source": [
    "## LLM chat that seems to have memory\n",
    "\n",
    "Actually, we just pack the whole conversation history to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dfd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = ollama.chat.completions.create(model='gemma3', messages=messages)\n",
    "    return response.choices[0].message.content, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8ed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Adam! I‚Äôm doing well, thank you for asking. \n",
      "\n",
      "Your name is Adam! üòä \n",
      "\n",
      "It's nice to meet you.\n"
     ]
    }
   ],
   "source": [
    "start_conversation = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?, my name is Adam.\"},\n",
    "    \n",
    "    ]\n",
    "\n",
    "reply1, history = chat(\"What is my name?\", start_conversation)\n",
    "print(reply1)\n",
    "\n",
    "reply2, history = chat(\"I live in Taiwan\", history)\n",
    "\n",
    "print(reply2)\n",
    "\n",
    "reply3, history = chat(\"Where do I live?\", history)\n",
    "print(reply3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63d5a8",
   "metadata": {},
   "source": [
    "# Build a simple AI app\n",
    "\n",
    "Gradio as frontend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
